"""
GitHub Pagesç”¨ã®Markdownãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
final_recommendations.csvã‚’èª­ã¿è¾¼ã¿ã€ç¾ã—ã„Markdownå½¢å¼ã§å‡ºåŠ›
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional
import logging
import re

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ReportGenerator:
    """ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, processed_data_dir: str = "data/processed", output_dir: str = "docs", 
                 raw_data_dir: str = "data/raw"):
        """
        åˆæœŸåŒ–
        
        Args:
            processed_data_dir: å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆGitHub Pagesç”¨ï¼‰
            raw_data_dir: ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆéŠ˜æŸ„åæƒ…å ±ç”¨ï¼‰
        """
        self.processed_data_dir = Path(processed_data_dir)
        self.output_dir = Path(output_dir)
        self.raw_data_dir = Path(raw_data_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # éŠ˜æŸ„åãƒãƒƒãƒ”ãƒ³ã‚°ã‚’èª­ã¿è¾¼ã¿
        self.company_names = self._load_company_names()
        
        # ã‚»ã‚¯ã‚¿ãƒ¼æƒ…å ±ã‚’èª­ã¿è¾¼ã¿
        self.sector_info = self._load_sector_info()
        
        logger.info(f"ReportGeneratoråˆæœŸåŒ–å®Œäº†")
    
    def _convert_to_hundred_million(self, value: Optional[float]) -> Optional[float]:
        """
        å€¤ã‚’å„„å††å˜ä½ã«å¤‰æ›
        
        Args:
            value: å…ƒã®å€¤
            
        Returns:
            å„„å††å˜ä½ã®å€¤ï¼ˆå°æ•°ç‚¹ç¬¬1ä½ã¾ã§ï¼‰
        """
        if value is None or pd.isna(value):
            return None
        return round(value / 100000000, 1)
    
    def _load_company_names(self) -> Dict[str, str]:
        """
        éŠ˜æŸ„åæƒ…å ±ã‚’èª­ã¿è¾¼ã‚€
        
        Returns:
            ticker -> company_name ã®è¾æ›¸
        """
        company_names = {}
        
        # jpx_tse_info.csvã‚’èª­ã¿è¾¼ã¿
        jpx_info_path = self.raw_data_dir / "jpx_tse_info.csv"
        if jpx_info_path.exists():
            try:
                jpx_df = pd.read_csv(jpx_info_path, encoding='utf-8-sig')
                
                # ã€Œã‚³ãƒ¼ãƒ‰ã€ã¨ã€ŒéŠ˜æŸ„åã€ã‚«ãƒ©ãƒ ã‚’ç›´æ¥ä½¿ç”¨
                if 'ã‚³ãƒ¼ãƒ‰' not in jpx_df.columns or 'éŠ˜æŸ„å' not in jpx_df.columns:
                    logger.error("ã€Œã‚³ãƒ¼ãƒ‰ã€ã¾ãŸã¯ã€ŒéŠ˜æŸ„åã€åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    return {}
                
                # å†…å›½æ ªå¼ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                if 'å¸‚å ´ãƒ»å•†å“åŒºåˆ†' in jpx_df.columns:
                    jpx_df = jpx_df[jpx_df['å¸‚å ´ãƒ»å•†å“åŒºåˆ†'].astype(str).str.contains('å†…å›½æ ªå¼', na=False)]
                
                for _, row in jpx_df.iterrows():
                    ticker = str(row['ã‚³ãƒ¼ãƒ‰']).strip()
                    name = str(row['éŠ˜æŸ„å']).strip()
                    # ã‚³ãƒ¼ãƒ‰æ•´å½¢ï¼š.0$ã‚’æ­£è¦è¡¨ç¾ã§é™¤å»ã—ã€4æ¡ã®æ–‡å­—åˆ—ï¼ˆ0åŸ‹ã‚ï¼‰ã«å¤‰æ›
                    ticker_clean = re.sub(r'\.0$', '', str(ticker)).strip()
                    # 4æ¡ã«æ•´å½¢
                    ticker_clean = ticker_clean.zfill(4)
                    if ticker_clean and name and ticker_clean.isdigit() and len(ticker_clean) == 4:
                        company_names[ticker_clean] = name
                logger.info(f"éŠ˜æŸ„åæƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(company_names)}ä»¶")
            except Exception as e:
                logger.warning(f"éŠ˜æŸ„åæƒ…å ±ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {str(e)}")
        else:
            logger.warning(f"éŠ˜æŸ„åæƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {jpx_info_path}")
        
        return company_names
    
    def _get_company_name(self, ticker: str) -> str:
        """
        éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‹ã‚‰éŠ˜æŸ„åã‚’å–å¾—
        
        Args:
            ticker: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰
            
        Returns:
            éŠ˜æŸ„åï¼ˆå–å¾—ã§ããªã„å ´åˆã¯ã‚³ãƒ¼ãƒ‰ã‚’è¿”ã™ï¼‰
        """
        # ã‚³ãƒ¼ãƒ‰æ•´å½¢ï¼š.Tã‚’é™¤å»ã—ã€.0$ã‚’æ­£è¦è¡¨ç¾ã§é™¤å»ã—ã¦ã‹ã‚‰4æ¡ã«æ•´å½¢
        ticker_clean = str(ticker).replace('.T', '').replace('T', '').strip()
        # re.sub()ã§.0$ã‚’é™¤å»ã—ã¦ã‹ã‚‰zfill(4)ã§4æ¡ã«æ•´å½¢
        ticker_clean = re.sub(r'\.0$', '', ticker_clean).strip()
        ticker_clean = ticker_clean.zfill(4)
        return self.company_names.get(ticker_clean, ticker)
    
    def _load_sector_info(self) -> Dict[str, str]:
        """
        ã‚»ã‚¯ã‚¿ãƒ¼ï¼ˆ33æ¥­ç¨®åŒºåˆ†ï¼‰æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€
        
        Returns:
            ticker -> sector_name ã®è¾æ›¸
        """
        sector_info = {}
        
        # jpx_tse_info.csvã‚’èª­ã¿è¾¼ã¿
        jpx_info_path = self.raw_data_dir / "jpx_tse_info.csv"
        if jpx_info_path.exists():
            try:
                jpx_df = pd.read_csv(jpx_info_path, encoding='utf-8-sig')
                
                # ã€Œã‚³ãƒ¼ãƒ‰ã€ã¨ã€Œ33æ¥­ç¨®åŒºåˆ†ã€ã‚«ãƒ©ãƒ ã‚’ç›´æ¥ä½¿ç”¨
                if 'ã‚³ãƒ¼ãƒ‰' not in jpx_df.columns or '33æ¥­ç¨®åŒºåˆ†' not in jpx_df.columns:
                    logger.error("ã€Œã‚³ãƒ¼ãƒ‰ã€ã¾ãŸã¯ã€Œ33æ¥­ç¨®åŒºåˆ†ã€åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    return {}
                
                # å†…å›½æ ªå¼ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                if 'å¸‚å ´ãƒ»å•†å“åŒºåˆ†' in jpx_df.columns:
                    jpx_df = jpx_df[jpx_df['å¸‚å ´ãƒ»å•†å“åŒºåˆ†'].astype(str).str.contains('å†…å›½æ ªå¼', na=False)]
                
                for _, row in jpx_df.iterrows():
                    ticker = str(row['ã‚³ãƒ¼ãƒ‰']).strip()
                    sector = str(row['33æ¥­ç¨®åŒºåˆ†']).strip()
                    # ã‚³ãƒ¼ãƒ‰æ•´å½¢ï¼š.0$ã‚’æ­£è¦è¡¨ç¾ã§é™¤å»ã—ã€4æ¡ã®æ–‡å­—åˆ—ï¼ˆ0åŸ‹ã‚ï¼‰ã«å¤‰æ›
                    ticker_clean = re.sub(r'\.0$', '', str(ticker)).strip()
                    # 4æ¡ã«æ•´å½¢
                    ticker_clean = ticker_clean.zfill(4)
                    if ticker_clean and sector and sector != '-' and ticker_clean.isdigit() and len(ticker_clean) == 4:
                        sector_info[ticker_clean] = sector
                logger.info(f"ã‚»ã‚¯ã‚¿ãƒ¼æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(sector_info)}ä»¶")
            except Exception as e:
                logger.warning(f"ã‚»ã‚¯ã‚¿ãƒ¼æƒ…å ±ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {str(e)}")
        else:
            logger.warning(f"ã‚»ã‚¯ã‚¿ãƒ¼æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {jpx_info_path}")
        
        return sector_info
    
    def _get_sector(self, ticker: str) -> Optional[str]:
        """
        éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ã‚»ã‚¯ã‚¿ãƒ¼ï¼ˆ33æ¥­ç¨®åŒºåˆ†ï¼‰ã‚’å–å¾—
        
        Args:
            ticker: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰
            
        Returns:
            ã‚»ã‚¯ã‚¿ãƒ¼åï¼ˆå–å¾—ã§ããªã„å ´åˆã¯Noneï¼‰
        """
        # ã‚³ãƒ¼ãƒ‰æ•´å½¢ï¼š.Tã‚’é™¤å»ã—ã€.0$ã‚’æ­£è¦è¡¨ç¾ã§é™¤å»ã—ã¦ã‹ã‚‰4æ¡ã«æ•´å½¢
        ticker_clean = str(ticker).replace('.T', '').replace('T', '').strip()
        # re.sub()ã§.0$ã‚’é™¤å»ã—ã¦ã‹ã‚‰zfill(4)ã§4æ¡ã«æ•´å½¢
        ticker_clean = re.sub(r'\.0$', '', ticker_clean).strip()
        ticker_clean = ticker_clean.zfill(4)
        return self.sector_info.get(ticker_clean)
    
    def _get_investment_badges(self, row: pd.Series) -> List[str]:
        """
        æŠ•è³‡ãƒã‚¤ãƒ³ãƒˆã®ãƒãƒƒã‚¸ã‚’ç”Ÿæˆï¼ˆShields.ioå½¢å¼ï¼‰
        
        Args:
            row: DataFrameã®è¡Œ
            
        Returns:
            ãƒãƒƒã‚¸ã®Markdownæ–‡å­—åˆ—ãƒªã‚¹ãƒˆ
        """
        badges = []
        
        # ROICãŒé«˜ã„å ´åˆï¼ˆ10%ä»¥ä¸Šï¼‰
        roic = row.get('roic')
        if roic is not None and not pd.isna(roic) and roic >= 10:
            badges.append("![ROIC](https://img.shields.io/badge/åŠ¹ç‡-é«˜ROIC-red)")
        
        # å£²ä¸Šæˆé•·ãŒé«˜ã„å ´åˆï¼ˆ10%ä»¥ä¸Šï¼‰
        revenue_growth = row.get('revenue_growth_rate')
        if revenue_growth is not None and not pd.isna(revenue_growth) and revenue_growth >= 10:
            badges.append("![Growth](https://img.shields.io/badge/æˆé•·-åŠ é€Ÿ-orange)")
        
        # ç„¡å€Ÿé‡‘
        if row.get('debt_free_flag') == True or row.get('is_debt_free') == True:
            badges.append("![Debt Free](https://img.shields.io/badge/è²¡å‹™-ç„¡å€Ÿé‡‘-blue)")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒªãƒƒãƒ
        if row.get('net_cash_status') == 'å®Ÿè³ªç„¡å€Ÿé‡‘':
            badges.append("![Cash Rich](https://img.shields.io/badge/è²¡å‹™-ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒªãƒƒãƒ-brightgreen)")
        
        return badges
    
    def _get_next_update_date(self) -> str:
        """
        æ¬¡å›ã®ãƒ‡ãƒ¼ã‚¿æ›´æ–°äºˆå®šæ—¥ã‚’è¨ˆç®—ï¼ˆæ¯é€±åœŸæ›œæ—¥ï¼‰
        
        Returns:
            æ¬¡å›æ›´æ–°äºˆå®šæ—¥ã®æ–‡å­—åˆ—
        """
        from datetime import datetime, timedelta
        
        today = datetime.now()
        # ä»Šæ—¥ãŒåœŸæ›œæ—¥ã‹ã©ã†ã‹ç¢ºèªï¼ˆweekday()ã§5ãŒåœŸæ›œæ—¥ï¼‰
        days_until_saturday = (5 - today.weekday()) % 7
        if days_until_saturday == 0:
            # ä»Šæ—¥ãŒåœŸæ›œæ—¥ãªã‚‰ã€æ¥é€±ã®åœŸæ›œæ—¥
            next_saturday = today + timedelta(days=7)
        else:
            # ä»Šé€±ã®åœŸæ›œæ—¥
            next_saturday = today + timedelta(days=days_until_saturday)
        
        return next_saturday.strftime("%Yå¹´%mæœˆ%dæ—¥ï¼ˆ%aï¼‰").replace('Sat', 'åœŸ').replace('Sun', 'æ—¥').replace('Mon', 'æœˆ').replace('Tue', 'ç«').replace('Wed', 'æ°´').replace('Thu', 'æœ¨').replace('Fri', 'é‡‘')
    
    def _format_percentage(self, value: Optional[float]) -> Optional[str]:
        """
        ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆå°æ•°ç‚¹ç¬¬1ä½ã¾ã§ï¼‰
        
        Args:
            value: ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸å€¤
            
        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸæ–‡å­—åˆ—ï¼ˆä¾‹: "12.3%"ï¼‰
        """
        if value is None or pd.isna(value):
            return None
        return f"{value:.1f}%"
    
    def _format_growth_rate(self, value: Optional[float]) -> Optional[str]:
        """
        æˆé•·ç‡ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆãƒ—ãƒ©ã‚¹ã®å ´åˆã¯+è¨˜å·ã‚’è¿½åŠ ã€é«˜ã„å ´åˆã¯å¤ªå­—ï¼‰
        
        Args:
            value: æˆé•·ç‡ï¼ˆ%ï¼‰
            
        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸæ–‡å­—åˆ—ï¼ˆä¾‹: "+10.5%", "**+15.2%**"ï¼‰
        """
        if value is None or pd.isna(value):
            return None
        
        formatted = f"{value:+.1f}%"
        
        # 10%ä»¥ä¸Šãªã‚‰å¤ªå­—
        if value >= 10:
            return f"**{formatted}**"
        
        return formatted
    
    def _format_roic(self, value: Optional[float]) -> Optional[str]:
        """
        ROICã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆ10%ä»¥ä¸Šãªã‚‰ğŸ”¥ã‚¢ã‚¤ã‚³ãƒ³ã‚’è¿½åŠ ï¼‰
        
        Args:
            value: ROICï¼ˆ%ï¼‰
            
        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸæ–‡å­—åˆ—ï¼ˆä¾‹: "12.3%", "15.5% ğŸ”¥"ï¼‰
        """
        if value is None or pd.isna(value):
            return None
        
        formatted = f"{value:.1f}%"
        
        # 10%ä»¥ä¸Šãªã‚‰ğŸ”¥ã‚¢ã‚¤ã‚³ãƒ³ã‚’è¿½åŠ 
        if value >= 10:
            return f"{formatted} ğŸ”¥"
        
        return formatted
    
    def _get_yahoo_finance_link(self, ticker: str) -> str:
        """
        Yahoo Financeã¸ã®ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆï¼ˆMarkdownå½¢å¼ï¼‰
        
        Args:
            ticker: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰
            
        Returns:
            Markdownãƒªãƒ³ã‚¯å½¢å¼ã®æ–‡å­—åˆ—
        """
        # ã‚³ãƒ¼ãƒ‰æ•´å½¢ï¼š.Tã‚’é™¤å»ã—ã€.0$ã‚’æ­£è¦è¡¨ç¾ã§é™¤å»ã—ã¦ã‹ã‚‰4æ¡ã«æ•´å½¢
        ticker_clean = str(ticker).replace('.T', '').replace('T', '').strip()
        # re.sub()ã§.0$ã‚’é™¤å»ã—ã¦ã‹ã‚‰zfill(4)ã§4æ¡ã«æ•´å½¢
        ticker_clean = re.sub(r'\.0$', '', ticker_clean).strip()
        ticker_clean = ticker_clean.zfill(4)
        url = f"https://finance.yahoo.co.jp/quote/{ticker_clean}.T"
        return f"[ğŸ“ˆ ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤º]({url})"
    
    def _get_status_tags(self, row: pd.Series) -> List[str]:
        """
        ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¿ã‚°ã‚’å–å¾—
        
        Args:
            row: DataFrameã®è¡Œ
            
        Returns:
            ã‚¿ã‚°ã®ãƒªã‚¹ãƒˆ
        """
        tags = []
        
        # ç„¡å€Ÿé‡‘ãƒ•ãƒ©ã‚°
        if row.get('debt_free_flag') == True or row.get('is_debt_free') == True:
            tags.append("ğŸ’ç„¡å€Ÿé‡‘")
        
        # å®Ÿè³ªç„¡å€Ÿé‡‘
        if row.get('net_cash_status') == 'å®Ÿè³ªç„¡å€Ÿé‡‘':
            tags.append("ğŸ’°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒªãƒƒãƒ")
        
        # é«˜æˆé•·ï¼ˆå£²ä¸Šæˆé•·ç‡ > 10%ï¼‰
        revenue_growth = row.get('revenue_growth_rate')
        if revenue_growth is not None and not pd.isna(revenue_growth) and revenue_growth > 10:
            tags.append("ğŸš€é«˜æˆé•·")
        
        return tags
    
    def _get_star_rank(self, score: Optional[float]) -> str:
        """
        ã‚¹ã‚³ã‚¢ã‹ã‚‰Sãƒ©ãƒ³ã‚¯åˆ¤å®š
        
        Args:
            score: ç·åˆã‚¹ã‚³ã‚¢
            
        Returns:
            ãƒ©ãƒ³ã‚¯ï¼ˆS, A, B, Cï¼‰
        """
        if score is None or pd.isna(score):
            return "C"
        
        if score >= 110:
            return "S"
        elif score >= 100:
            return "A"
        elif score >= 80:
            return "B"
        else:
            return "C"
    
    def generate_markdown(self, df: pd.DataFrame) -> str:
        """
        Markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
        
        Args:
            df: final_recommendations.csvã®DataFrame
            
        Returns:
            Markdownå½¢å¼ã®æ–‡å­—åˆ—
        """
        if df.empty:
            return "# æ¨å¥¨éŠ˜æŸ„ãƒ¬ãƒãƒ¼ãƒˆ\n\nãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\n"
        
        # missing_criticalã§åˆ†é›¢
        # missing_criticalãŒTrueã®éŠ˜æŸ„ã‚’å‚è€ƒãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦åˆ†é›¢
        if 'missing_critical' in df.columns:
            # ãƒ–ãƒ¼ãƒ«å€¤ã¾ãŸã¯æ–‡å­—åˆ—ã®'True'/'False'ã«å¯¾å¿œ
            df['missing_critical'] = df['missing_critical'].astype(str).str.lower().isin(['true', '1', 'yes'])
            main_df = df[~df['missing_critical']].copy()
            reference_df = df[df['missing_critical']].copy()
        else:
            main_df = df.copy()
            reference_df = pd.DataFrame()
        
        # ç¾åœ¨ã®æ—¥æ™‚
        now = datetime.now()
        update_time = now.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")
        next_update = self._get_next_update_date()
        
        # Sãƒ©ãƒ³ã‚¯éŠ˜æŸ„æ•°ï¼ˆå‚è€ƒãƒ‡ãƒ¼ã‚¿ã‚’é™¤ãï¼‰
        s_rank_count = len(main_df[main_df.get('total_score', 0) >= 110])
        
        # Header
        markdown = f"""# ğŸ“Š æ—¥æœ¬æ ª æˆé•·Ã—å‰²å®‰ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°çµæœ

<div align="center">

![æ›´æ–°æ—¥æ™‚](https://img.shields.io/badge/æ›´æ–°æ—¥æ™‚-{update_time}-blue)
![æ³¨ç›®éŠ˜æŸ„æ•°](https://img.shields.io/badge/ä»Šæ—¥ã®æ³¨ç›®éŠ˜æŸ„æ•°-{s_rank_count}éŠ˜æŸ„-brightgreen)
![æ¬¡å›æ›´æ–°](https://img.shields.io/badge/æ¬¡å›æ›´æ–°-{next_update}-orange)

</div>

---

## ğŸ† Top Picks (Sãƒ©ãƒ³ã‚¯éŠ˜æŸ„)

"""
        
        # Sãƒ©ãƒ³ã‚¯éŠ˜æŸ„ï¼ˆScore 110+ï¼‰ã‚’æŠ½å‡ºï¼ˆå‚è€ƒãƒ‡ãƒ¼ã‚¿ã‚’é™¤ãï¼‰
        s_rank_df = main_df[main_df.get('total_score', 0) >= 110].copy()
        
        if not s_rank_df.empty:
            # ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§Top Picksã‚’è¡¨ç¤º
            markdown += "\n\n<div style=\"overflow-x: auto;\">\n\n"
            markdown += "| é †ä½ | éŠ˜æŸ„å | æ¥­ç¨® | ã‚¹ã‚³ã‚¢ | ROIC | æˆé•·ç‡ | ãƒãƒƒã‚¸ | ãƒªãƒ³ã‚¯ |\n"
            markdown += "|:----:|:------:|:----:|:-----:|:----:|:------:|:------:|:------:|\n"
            
            for idx, row in s_rank_df.iterrows():
                rank = row.get('rank', idx + 1)
                ticker = row.get('ticker', 'N/A')
                company_name = self._get_company_name(ticker)
                sector = self._get_sector(ticker)
                score = row.get('total_score', 0)
                roic = self._format_roic(row.get('roic'))
                growth_rate = self._format_growth_rate(row.get('revenue_growth_rate'))
                
                # æ¥­ç¨®è¡¨ç¤º
                sector_display = sector if sector else "-"
                
                # ãƒãƒƒã‚¸ã‚’å–å¾—ï¼ˆShields.ioå½¢å¼ï¼‰
                investment_badges = self._get_investment_badges(row)
                badges_str = " ".join(investment_badges) if investment_badges else "-"
                
                # Yahoo Financeãƒªãƒ³ã‚¯ï¼ˆMarkdownå½¢å¼ï¼‰
                chart_link = self._get_yahoo_finance_link(ticker)
                
                # å€¤ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                roic_str = roic if roic else "N/A"
                growth_str = growth_rate if growth_rate else "N/A"
                
                markdown += f"| {rank} | {company_name} | {sector_display} | {score:.0f} | {roic_str} | {growth_str} | {badges_str} | {chart_link} |\n"
            
            markdown += "\n</div>\n\n"
        else:
            markdown += "Sãƒ©ãƒ³ã‚¯éŠ˜æŸ„ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\n\n"
        
        # Full Ranking Table
        markdown += """---

## ğŸ“ˆ Full Ranking (å…¨éŠ˜æŸ„æ¯”è¼ƒ)\n\n"
        markdown += "<div style=\"overflow-x: auto;\">\n\n"
        markdown += "| Rank | éŠ˜æŸ„å | Ticker | Score | ROIC | æˆé•·ç‡ | è²¡å‹™ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ | å£²ä¸Šé«˜<br>(å„„å††) | å–¶æ¥­åˆ©ç›Š<br>(å„„å††) |\n"
        markdown += "|:----:|:------:|:------:|:-----:|:----:|:------:|:--------------:|:----------------:|:-----------------:|\n"
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œã‚’ç”Ÿæˆï¼ˆå‚è€ƒãƒ‡ãƒ¼ã‚¿ã‚’é™¤ãï¼‰
        for idx, row in main_df.iterrows():
            rank = row.get('rank', idx + 1)
            ticker = row.get('ticker', 'N/A')
            company_name = self._get_company_name(ticker)
            sector = self._get_sector(ticker)
            score = row.get('total_score', 0)
            roic = self._format_roic(row.get('roic'))
            growth_rate = self._format_growth_rate(row.get('revenue_growth_rate'))
            revenue = self._convert_to_hundred_million(row.get('revenue'))
            operating_income = self._convert_to_hundred_million(row.get('operating_income'))
            
            tags = self._get_status_tags(row)
            status_str = " ".join(tags) if tags else "-"
            
            # ã‚»ã‚¯ã‚¿ãƒ¼æƒ…å ±ã‚’è¿½åŠ 
            company_display = f"{company_name} [{sector}]" if sector else company_name
            
            # å€¤ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            roic_str = roic if roic else "N/A"
            growth_str = growth_rate if growth_rate else "N/A"
            revenue_str = f"{revenue:.1f}" if revenue is not None else "N/A"
            op_income_str = f"{operating_income:.1f}" if operating_income is not None else "N/A"
            
            # Yahoo Financeãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆ
            ticker_link = self._get_yahoo_finance_link(ticker)
            
            markdown += f"| {rank} | {company_display} | {ticker_link} | {score:.0f} | {roic_str} | {growth_str} | {status_str} | {revenue_str} | {op_income_str} |\n"
        
        markdown += "\n</div>\n\n"
        
        # å‚è€ƒãƒ‡ãƒ¼ã‚¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆmissing_criticalãŒTrueã®éŠ˜æŸ„ï¼‰
        if not reference_df.empty:
            markdown += "---\n\n"

## âš ï¸ å‚è€ƒãƒ‡ãƒ¼ã‚¿ï¼ˆé‡è¦ãƒ‡ãƒ¼ã‚¿æ¬ æã‚ã‚Šï¼‰\n\n"
            markdown += "ä»¥ä¸‹ã®éŠ˜æŸ„ã¯é‡è¦ãªè²¡å‹™ãƒ‡ãƒ¼ã‚¿ãŒæ¬ æã—ã¦ã„ã‚‹ãŸã‚ã€å‚è€ƒæƒ…å ±ã¨ã—ã¦è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚\n\n"
            markdown += "<div style=\"overflow-x: auto;\">\n\n"
            markdown += "| Rank | éŠ˜æŸ„å | Ticker | Score | ROIC | æˆé•·ç‡ | è²¡å‹™ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ | å£²ä¸Šé«˜<br>(å„„å††) | å–¶æ¥­åˆ©ç›Š<br>(å„„å††) | æ¬ æé …ç›® |\n"
            markdown += "|:----:|:------:|:------:|:-----:|:----:|:------:|:--------------:|:----------------:|:-----------------:|:--------:|\n"
            
            # å‚è€ƒãƒ‡ãƒ¼ã‚¿ã®ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œã‚’ç”Ÿæˆ
            for idx, row in reference_df.iterrows():
                rank = row.get('rank', idx + 1)
                ticker = row.get('ticker', 'N/A')
                company_name = self._get_company_name(ticker)
                score = row.get('total_score', 0)
                roic = self._format_roic(row.get('roic'))
                growth_rate = self._format_growth_rate(row.get('revenue_growth_rate'))
                revenue = self._convert_to_hundred_million(row.get('revenue'))
                operating_income = self._convert_to_hundred_million(row.get('operating_income'))
                
                tags = self._get_status_tags(row)
                status_str = " ".join(tags) if tags else "-"
                
                # æ¬ æé …ç›®ã‚’å–å¾—
                missing_items = row.get('missing_items', '')
                if isinstance(missing_items, str):
                    if missing_items.startswith('[') and missing_items.endswith(']'):
                        # ãƒªã‚¹ãƒˆå½¢å¼ã®æ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹
                        import ast
                        try:
                            missing_list = ast.literal_eval(missing_items)
                            missing_str = ', '.join(missing_list) if missing_list else '-'
                        except:
                            missing_str = missing_items if missing_items else '-'
                    else:
                        missing_str = missing_items if missing_items else '-'
                else:
                    missing_str = '-'
                
                # å€¤ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                roic_str = roic if roic else "N/A"
                growth_str = growth_rate if growth_rate else "N/A"
                revenue_str = f"{revenue:.1f}" if revenue is not None else "N/A"
                op_income_str = f"{operating_income:.1f}" if operating_income is not None else "N/A"
                
                # Yahoo Financeãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆ
                ticker_link = self._get_yahoo_finance_link(ticker)
                
                markdown += f"| {rank} | {company_name} | {ticker_link} | {score:.0f} | {roic_str} | {growth_str} | {status_str} | {revenue_str} | {op_income_str} | {missing_str} |\n"
            
            markdown += "\n</div>\n\n"
        
        markdown += """---

## ğŸ“ å‡¡ä¾‹

- ğŸ’ç„¡å€Ÿé‡‘: æœ‰åˆ©å­è² å‚µãŒã‚¼ãƒ­ã®éŠ˜æŸ„
- ğŸ’°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒªãƒƒãƒ: ç¾é é‡‘ãŒæœ‰åˆ©å­è² å‚µã‚’ä¸Šå›ã‚‹éŠ˜æŸ„ï¼ˆå®Ÿè³ªç„¡å€Ÿé‡‘ï¼‰
- ğŸš€é«˜æˆé•·: å£²ä¸Šæˆé•·ç‡ãŒ10%ã‚’è¶…ãˆã‚‹éŠ˜æŸ„

## ğŸ“Š ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°

- **Sãƒ©ãƒ³ã‚¯**: 110ç‚¹ä»¥ä¸Šï¼ˆãƒ‡ãƒ¼ã‚¿å“è³ª100ç‚¹ + ãƒœãƒ¼ãƒŠã‚¹10ç‚¹ä»¥ä¸Šï¼‰
- **Aãƒ©ãƒ³ã‚¯**: 100-109ç‚¹
- **Bãƒ©ãƒ³ã‚¯**: 80-99ç‚¹
- **Cãƒ©ãƒ³ã‚¯**: 80ç‚¹æœªæº€

---

*æœ€çµ‚æ›´æ–°: {update_time}*  
*æ¬¡å›æ›´æ–°äºˆå®š: {next_update}*

""".format(update_time=update_time, next_update=next_update)
        
        return markdown
    
    def generate_report(self, filename: str = "final_recommendations.csv") -> str:
        """
        ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ä¿å­˜
        
        Args:
            filename: å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«å
            
        Returns:
            ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        csv_path = self.processed_data_dir / filename
        if not csv_path.exists():
            logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
            return ""
        
        try:
            df = pd.read_csv(csv_path, encoding='utf-8-sig')
            logger.info(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df)}éŠ˜æŸ„")
        except Exception as e:
            logger.error(f"CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return ""
        
        # Markdownã‚’ç”Ÿæˆ
        markdown = self.generate_markdown(df)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        output_path = self.output_dir / "index.md"
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(markdown)
        
        logger.info(f"ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å®Œäº†: {output_path}")
        return str(output_path)


# ============================================
# ãƒ¡ã‚¤ãƒ³é–¢æ•°
# ============================================
def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("=" * 60)
    print("GitHub Pagesç”¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
    print("=" * 60)
    
    generator = ReportGenerator()
    
    # ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
    filepath = generator.generate_report()
    
    if filepath:
        print(f"\nãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {filepath}")
    else:
        print("ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")


if __name__ == "__main__":
    main()
